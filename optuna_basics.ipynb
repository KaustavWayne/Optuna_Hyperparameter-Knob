{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zjjKm0Ort1Z",
        "outputId": "d497b869-e4a7-44eb-f91c-d415722fb213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.9.0 optuna-4.5.0\n"
          ]
        }
      ],
      "source": [
        "# Install Optuna (if needed)\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i37nK4losSUH"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CzvAwFkLsJj2"
      },
      "outputs": [],
      "source": [
        "# Load the Pima Indian Diabetes dataset (from UCI repository)\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
        "    'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(url, names=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuAQaB_asYBn",
        "outputId": "d8b3836d-d511-47bc-f812-952685bf3ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pregnancies                 0\n",
            "Glucose                     0\n",
            "BloodPressure               0\n",
            "SkinThickness               0\n",
            "Insulin                     0\n",
            "BMI                         0\n",
            "DiabetesPedigreeFunction    0\n",
            "Age                         0\n",
            "Outcome                     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Data preprocessing\n",
        "# Replace zero values with NaN in columns where zero is not a valid value\n",
        "cols_with_missing_vals = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "df[cols_with_missing_vals] = df[cols_with_missing_vals].replace(0, np.nan)\n",
        "\n",
        "# Impute the missing values with the mean of the respective column\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Check if there are any remaining missing values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdbWWWj6scCO",
        "outputId": "a6033150-5846-4c31-f74d-a5cd31ecbc03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape: (537, 8)\n",
            "Test set shape: (231, 8)\n"
          ]
        }
      ],
      "source": [
        "# Split into features (X) and target (y)\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split data into training and test sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Optional: Scale the data for better model performance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Check the shape of the data\n",
        "print(f'Training set shape: {X_train.shape}')\n",
        "print(f'Test set shape: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MlRehUlBsdLW"
      },
      "outputs": [],
      "source": [
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Suggest values for the hyperparameters\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "\n",
        "    # Create the RandomForestClassifier with suggested hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Perform 3-fold cross-validation and calculate accuracy\n",
        "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
        "\n",
        "    return score  # Return the accuracy score for Optuna to maximize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PMGvFogsf-m",
        "outputId": "54181317-ba93-46d2-aaa9-a66fb64f8bcf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-09-12 16:11:13,703] A new study created in memory with name: no-name-04f89f26-9b4a-4f11-b6d9-0d88224f617b\n",
            "[I 2025-09-12 16:11:14,999] Trial 0 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 116, 'max_depth': 13, 'min_samples_split': 2}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:16,126] Trial 1 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 177, 'max_depth': 15, 'min_samples_split': 2}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:16,958] Trial 2 finished with value: 0.7579143389199254 and parameters: {'n_estimators': 146, 'max_depth': 4, 'min_samples_split': 4}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:18,382] Trial 3 finished with value: 0.7541899441340782 and parameters: {'n_estimators': 142, 'max_depth': 4, 'min_samples_split': 5}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:18,996] Trial 4 finished with value: 0.7616387337057727 and parameters: {'n_estimators': 67, 'max_depth': 19, 'min_samples_split': 3}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:19,376] Trial 5 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 61, 'max_depth': 16, 'min_samples_split': 6}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:19,806] Trial 6 finished with value: 0.7653631284916201 and parameters: {'n_estimators': 66, 'max_depth': 16, 'min_samples_split': 7}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:20,428] Trial 7 finished with value: 0.7616387337057727 and parameters: {'n_estimators': 101, 'max_depth': 14, 'min_samples_split': 5}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:21,251] Trial 8 finished with value: 0.7541899441340782 and parameters: {'n_estimators': 137, 'max_depth': 6, 'min_samples_split': 8}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:21,956] Trial 9 finished with value: 0.7653631284916201 and parameters: {'n_estimators': 90, 'max_depth': 18, 'min_samples_split': 4}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:24,027] Trial 10 finished with value: 0.7635009310986964 and parameters: {'n_estimators': 193, 'max_depth': 10, 'min_samples_split': 9}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:26,135] Trial 11 finished with value: 0.7635009310986964 and parameters: {'n_estimators': 181, 'max_depth': 11, 'min_samples_split': 2}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:27,233] Trial 12 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 171, 'max_depth': 13, 'min_samples_split': 2}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:27,957] Trial 13 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 112, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:28,998] Trial 14 finished with value: 0.7579143389199254 and parameters: {'n_estimators': 162, 'max_depth': 14, 'min_samples_split': 10}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:29,771] Trial 15 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 121, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:31,038] Trial 16 finished with value: 0.7635009310986964 and parameters: {'n_estimators': 200, 'max_depth': 16, 'min_samples_split': 3}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:31,616] Trial 17 finished with value: 0.7597765363128491 and parameters: {'n_estimators': 87, 'max_depth': 12, 'min_samples_split': 4}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:32,560] Trial 18 finished with value: 0.7635009310986964 and parameters: {'n_estimators': 150, 'max_depth': 18, 'min_samples_split': 6}. Best is trial 0 with value: 0.7709497206703911.\n",
            "[I 2025-09-12 16:11:33,396] Trial 19 finished with value: 0.7765363128491621 and parameters: {'n_estimators': 130, 'max_depth': 20, 'min_samples_split': 2}. Best is trial 19 with value: 0.7765363128491621.\n",
            "[I 2025-09-12 16:11:34,219] Trial 20 finished with value: 0.7653631284916201 and parameters: {'n_estimators': 126, 'max_depth': 20, 'min_samples_split': 3}. Best is trial 19 with value: 0.7765363128491621.\n",
            "[I 2025-09-12 16:11:35,851] Trial 21 finished with value: 0.7653631284916201 and parameters: {'n_estimators': 159, 'max_depth': 15, 'min_samples_split': 2}. Best is trial 19 with value: 0.7765363128491621.\n",
            "[I 2025-09-12 16:11:37,109] Trial 22 finished with value: 0.7783985102420856 and parameters: {'n_estimators': 127, 'max_depth': 18, 'min_samples_split': 2}. Best is trial 22 with value: 0.7783985102420856.\n",
            "[I 2025-09-12 16:11:37,956] Trial 23 finished with value: 0.7616387337057727 and parameters: {'n_estimators': 129, 'max_depth': 20, 'min_samples_split': 3}. Best is trial 22 with value: 0.7783985102420856.\n",
            "[I 2025-09-12 16:11:38,691] Trial 24 finished with value: 0.7653631284916201 and parameters: {'n_estimators': 110, 'max_depth': 17, 'min_samples_split': 4}. Best is trial 22 with value: 0.7783985102420856.\n",
            "[I 2025-09-12 16:11:39,335] Trial 25 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 95, 'max_depth': 19, 'min_samples_split': 5}. Best is trial 22 with value: 0.7783985102420856.\n",
            "[I 2025-09-12 16:11:40,078] Trial 26 finished with value: 0.7802607076350093 and parameters: {'n_estimators': 115, 'max_depth': 18, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:40,928] Trial 27 finished with value: 0.7597765363128491 and parameters: {'n_estimators': 133, 'max_depth': 18, 'min_samples_split': 3}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:41,416] Trial 28 finished with value: 0.7597765363128491 and parameters: {'n_estimators': 78, 'max_depth': 20, 'min_samples_split': 4}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:42,092] Trial 29 finished with value: 0.7746741154562384 and parameters: {'n_estimators': 106, 'max_depth': 17, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:42,938] Trial 30 finished with value: 0.7746741154562383 and parameters: {'n_estimators': 118, 'max_depth': 19, 'min_samples_split': 7}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:44,052] Trial 31 finished with value: 0.7728119180633147 and parameters: {'n_estimators': 105, 'max_depth': 17, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:45,216] Trial 32 finished with value: 0.7746741154562384 and parameters: {'n_estimators': 117, 'max_depth': 18, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:45,862] Trial 33 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 99, 'max_depth': 17, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:46,775] Trial 34 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 149, 'max_depth': 15, 'min_samples_split': 3}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:47,464] Trial 35 finished with value: 0.7653631284916201 and parameters: {'n_estimators': 82, 'max_depth': 20, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:48,838] Trial 36 finished with value: 0.7653631284916201 and parameters: {'n_estimators': 139, 'max_depth': 19, 'min_samples_split': 3}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:49,976] Trial 37 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 125, 'max_depth': 17, 'min_samples_split': 4}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:50,684] Trial 38 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 109, 'max_depth': 14, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:51,611] Trial 39 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 142, 'max_depth': 16, 'min_samples_split': 3}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:52,082] Trial 40 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 74, 'max_depth': 19, 'min_samples_split': 5}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:52,848] Trial 41 finished with value: 0.7746741154562384 and parameters: {'n_estimators': 117, 'max_depth': 18, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:53,706] Trial 42 finished with value: 0.7802607076350093 and parameters: {'n_estimators': 133, 'max_depth': 18, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:54,467] Trial 43 finished with value: 0.7560521415270017 and parameters: {'n_estimators': 131, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:55,437] Trial 44 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 156, 'max_depth': 15, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:56,614] Trial 45 finished with value: 0.7765363128491619 and parameters: {'n_estimators': 134, 'max_depth': 19, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:57,429] Trial 46 finished with value: 0.7635009310986964 and parameters: {'n_estimators': 135, 'max_depth': 6, 'min_samples_split': 3}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:58,323] Trial 47 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 144, 'max_depth': 19, 'min_samples_split': 2}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:11:59,439] Trial 48 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 168, 'max_depth': 20, 'min_samples_split': 4}. Best is trial 26 with value: 0.7802607076350093.\n",
            "[I 2025-09-12 16:12:00,574] Trial 49 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 123, 'max_depth': 18, 'min_samples_split': 8}. Best is trial 26 with value: 0.7802607076350093.\n"
          ]
        }
      ],
      "source": [
        "# Create a study object and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')  # We aim to maximize accuracy\n",
        "study.optimize(objective, n_trials=50)  # Run 50 trials to find the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHw5G72_skTe",
        "outputId": "51a54f09-b7a3-4dc5-cac5-ae437d18a195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial accuracy: 0.7802607076350093\n",
            "Best hyperparameters: {'n_estimators': 115, 'max_depth': 18, 'min_samples_split': 2}\n"
          ]
        }
      ],
      "source": [
        "# Print the best result\n",
        "print(f'Best trial accuracy: {study.best_trial.value}')\n",
        "print(f'Best hyperparameters: {study.best_trial.params}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh7I1D2-sqf4",
        "outputId": "b163f6b9-0ad8-4d3f-b61c-375b20b06129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy with best hyperparameters: 0.75\n"
          ]
        }
      ],
      "source": [
        "# Train a RandomForestClassifier using the best hyperparameters from Optuna\n",
        "best_model = RandomForestClassifier(**study.best_trial.params, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy on the test set\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f'Test Accuracy with best hyperparameters: {test_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Samplers in Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import optuna\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    # Suggest values for the hyperparameters\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "\n",
        "    # Create the RandomForestClassifier with suggested hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Perform 3-fold cross-validation and calculate accuracy\n",
        "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
        "\n",
        "    return score  # Return the accuracy score for Optuna to maximize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a study with RandomSampler (aim to maximize accuracy)\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler())\n",
        "study.optimize(objective, n_trials=50)  # Run 50 trials to find the best hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the best result\n",
        "print(f'Best trial accuracy: {study.best_trial.value}')\n",
        "print(f'Best hyperparameters: {study.best_trial.params}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a RandomForestClassifier using the best hyperparameters from Optuna\n",
        "best_model = RandomForestClassifier(**study.best_trial.params, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy on the test set\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f'Test Accuracy with best hyperparameters: {test_accuracy:.2f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative: Using GridSampler with a defined search space\n",
        "search_space = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'max_depth': [5, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a study and optimize it using GridSampler\n",
        "study_grid = optuna.create_study(direction='maximize', sampler=optuna.samplers.GridSampler(search_space))\n",
        "study_grid.optimize(objective)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a RandomForestClassifier using the best hyperparameters from Optuna\n",
        "best_model = RandomForestClassifier(**study.best_trial.params, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy on the test set\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f'Test Accuracy with best hyperparameters: {test_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install cmaes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import optuna\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    # Suggest values for the hyperparameters\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "\n",
        "    # Create the RandomForestClassifier with suggested hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Perform 3-fold cross-validation and calculate accuracy\n",
        "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
        "\n",
        "    return score  # Return the accuracy score for Optuna to maximize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a study and optimize it using CmaEsSampler\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.CmaEsSampler())\n",
        "study.optimize(objective, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the best result\n",
        "print(f'Best trial accuracy: {study.best_trial.value}')\n",
        "print(f'Best hyperparameters: {study.best_trial.params}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a RandomForestClassifier using the best hyperparameters from Optuna\n",
        "best_model = RandomForestClassifier(**study.best_trial.params, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy on the test set\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f'Test Accuracy with best hyperparameters: {test_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the trials as a DataFrame for analysis\n",
        "trials_df = study.trials_dataframe()\n",
        "print(trials_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the sampler and pruner used\n",
        "print(f\"Study sampler: {study.sampler}\")\n",
        "print(f\"Study pruner: {study.pruner}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For visualizations\n",
        "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_slice, plot_contour, plot_param_importances\n",
        "\n",
        "# 1. Optimization History\n",
        "plot_optimization_history(study).show()\n",
        "\n",
        "# 2. Parallel Coordinate Plot\n",
        "plot_parallel_coordinate(study).show()\n",
        "\n",
        "# 3. Slice Plot\n",
        "plot_slice(study).show()\n",
        "\n",
        "# 4. Contour Plot\n",
        "plot_contour(study).show()\n",
        "\n",
        "# 5. Hyperparameter Importance\n",
        "plot_param_importances(study).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimizing Multiple ML Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing the required libraries\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import optuna\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Choose the algorithm to tune\n",
        "    classifier_name = trial.suggest_categorical('classifier', ['SVM', 'RandomForest', 'GradientBoosting'])\n",
        "    \n",
        "    if classifier_name == 'SVM':\n",
        "        # SVM hyperparameters\n",
        "        C = trial.suggest_float('C', 0.1, 100, log=True)\n",
        "        kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
        "        gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
        "        model = SVC(C=C, kernel=kernel, gamma=gamma, random_state=42)\n",
        "\n",
        "    elif classifier_name == 'RandomForest':\n",
        "        # Random Forest hyperparameters\n",
        "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "        max_depth = trial.suggest_int('max_depth', 3, 20)\n",
        "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "        bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "        \n",
        "        model = RandomForestClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=min_samples_split,\n",
        "            min_samples_leaf=min_samples_leaf,\n",
        "            bootstrap=bootstrap,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    elif classifier_name == 'GradientBoosting':\n",
        "        # Gradient Boosting hyperparameters\n",
        "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
        "        max_depth = trial.suggest_int('max_depth', 3, 20)\n",
        "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "        \n",
        "        model = GradientBoostingClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            learning_rate=learning_rate,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=min_samples_split,\n",
        "            min_samples_leaf=min_samples_leaf,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    # Perform cross-validation and return the mean accuracy\n",
        "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
        "    return score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a study and optimize it\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve the best_trial\n",
        "best_trial = study.best_trial\n",
        "print(\"Best_trial parameters:\", best_trial.params)\n",
        "print(\"Best_trial accuracy:\", best_trial.value)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze the trials dataframe\n",
        "trials_df = study.trials_dataframe()\n",
        "print(trials_df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count the number of trials for each classifier\n",
        "classifier_counts = study.trials_dataframe()['params_classifier'].value_counts()\n",
        "print(\"Classifier trial counts:\")\n",
        "print(classifier_counts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate mean accuracy for each classifier\n",
        "classifier_means = study.trials_dataframe().groupby('params_classifier')['value'].mean()\n",
        "print(\"Mean accuracy by classifier:\")\n",
        "print(classifier_means)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Optimization History \n",
        "\n",
        "plot_optimizaton_history(study).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.Hyperparameter Importance\n",
        "\n",
        "plot_param_importances(study).show"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
